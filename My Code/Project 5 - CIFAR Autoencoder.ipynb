{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLNg0PjQ6we23xp8PDVIml"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Task\n","- create an auto encoder\n","(3x32x32) --> (16x16x16) --> (32x8x8) --> (64xx4x4) --> (32x8x8) -->(16x16x16) (3x32x32)"],"metadata":{"id":"Nrb94F7KOWml"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtfIXZG-Nnf5"},"outputs":[],"source":["import torchvision\n","import torchvision.transforms as transforms\n","# import libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader,TensorDataset,SubsetRandomSampler\n","from sklearn.model_selection import train_test_split\n","\n","# for getting summary info on models\n","from torchsummary import summary\n","\n","import matplotlib.pyplot as plt\n","from IPython import display\n","display.set_matplotlib_formats('svg')\n","device = torch.device('cude' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","source":["transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","trainset = torchvision.datasets.CIFAR10(root='./data',\n","                                        train=True,\n","                                        download=True,\n","                                        transform=transforms)\n","testset = torchvision.datasets.CIFAR10(root='./data',\n","                                        train=False,\n","                                        download=True,\n","                                        transform=transforms)\n"],"metadata":{"id":"-7bS4c2wPFTz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transformations\n","transform = T.Compose([ T.ToTensor(),\n","                        T.Normalize([.5,.5,.5],[.5,.5,.5])\n","                       ])\n","\n","# import the data and simultaneously apply the transform\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform)\n","testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# transform to dataloaders\n","batchsize    = 32\n","train_loader = DataLoader(trainset,batch_size=batchsize,shuffle=True,drop_last=True)\n","test_loader  = DataLoader(testset, batch_size=len(testset))"],"metadata":{"id":"-NkggYmgPbl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a class for the model\n","def makeTheNet():\n","\n","  class emnistnet(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","      # encoding layer\n","      self.enc = nn.Sequential(\n","          nn.Conv2d(\n","              in_channels=3,\n","              out_channels=16,\n","              kernel_size=4,\n","              padding=1\n","              stride=2),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2,2),\n","          nn.Conv2d(6,4,3,padding=1),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2,2)\n","          )\n","\n","      # decoding layer\n","      self.dec = nn.Sequential(\n","          nn.ConvTranspose2d(4,6,3,2),\n","          nn.ReLU(),\n","          nn.ConvTranspose2d(6,1,3,2),\n","          )\n","\n","\n","\n","    def forward(self,x):\n","      return self.dec(self.enc(x))\n","\n","  # create the model instance\n","  net = emnistnet()\n","\n","  # loss function\n","  lossfun = nn.CrossEntropyLoss()\n","\n","  # optimizer\n","  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n","\n","  return net,lossfun,optimizer"],"metadata":{"id":"50s6nQrMPnv6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","def trainTheModel(net, lossfun, optimizer, train_loader, test_loader):\n","  numepochs = 15\n","\n","\n","  # net.to(device)\n","\n","  # initialize losses\n","  trainLoss = torch.zeros(numepochs)\n","  valLoss  = torch.zeros(numepochs)\n","  trainAcc  = torch.zeros(numepochs)\n","  valAcc   = torch.zeros(numepochs)\n","\n","\n","  # loop over epochs\n","  for epochi in range(numepochs):\n","\n","    # loop over training data batches\n","    net.train()\n","    batchLoss = []\n","    batchAcc  = []\n","    for X,y in train_loader:\n","\n","      # push data to GPU\n","      X = X.to(device)\n","      y = y.to(device)\n","\n","      # forward pass and loss\n","      yHat = net(X)\n","      loss = lossfun(yHat,y)\n","\n","      # backprop\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # loss and Accuracy from this batch\n","      batchLoss.append(loss.item())\n","      batchAcc.append( torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n","    # end of batch loop...\n","\n","    # and get average losses and Accuracy rates across the batches\n","    trainLoss[epochi] = np.mean(batchLoss)\n","    trainAcc[epochi]  = 100*np.mean(batchAcc)\n","\n","\n","    net.eval()\n","    # test performance\n","    valBatchLoss = []\n","    valBatchAcc  = []\n","    for X,y in val_loader: # extract X,y from test dataloader\n","\n","    # push data to GPU\n","      X = X.to(device)\n","      y = y.to(device)\n","\n","      with torch.no_grad(): # deactivates autograd\n","        yHat = net(X)\n","        loss = lossfun(yHat,y)\n","\n","      valBatchLoss.append(loss.item())\n","      valBatchAcc.append( torch.mean((torch.argmax(yHat,axis=1) == y).float()).item() )\n","    # get loss and Accor rate from the test batch\n","    valLoss[epochi] = loss.item()\n","    valAcc[epochi]  = 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item()\n","\n","  # end epochs\n","\n","  # function output\n","  return trainLoss,valLoss,trainAcc,valAcc,net\n"],"metadata":{"id":"PKJvCqyeWjxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net, lossfun, optimizer = makeTheNet()\n","trainLoss,valLoss,trainAcc,valAcc,net = trainTheModel(net, lossfun, optimizer, train_loader, test_loader)"],"metadata":{"id":"-nt29Dw6XRQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net.eval()\n","X,y = next(iter(test_loader))\n","X = X.to(device)\n","y = y.to(device)\n","with torch.no_grad():\n","  yHat = net(X)\n","  loss = lossfun(yHat, y)\n","\n","testLoss = loss.item()\n","testAcc  = 100*torch.mean((torch.argmax(yHat,axis=1) == y).float()).item()"],"metadata":{"id":"vxcGSzxDXqF5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(2,1,figsize=(5,6))\n","\n","\n","ax[0].plot(trainLoss,'s-',label='Train')\n","ax[0].plot(valLoss,'o-',label='Val')\n","ax[0].plot(testLoss,'o-',label='Val')\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss (CEL)')\n","ax[0].set_title('Model loss')"],"metadata":{"id":"lMAri2GDXbCs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(2,10,figsize=(14,4))\n","yHat.cpu()\n","for i in range(10):\n","  #Model output\n","  pic = yHat[i,:,:,:].detach().numpy().transpose((1,2,0))\n","  pic = pic/2 + .5 # undo normalization\n","  axs[0,i].imshow(pic)\n","  axs[0,i].set_title(f'[ {np.min(pic):.2f}, {np.max(pic):.2f} ]',fontsize=10)\n","  axs[0,i].axis('off')\n","\n","  # origional images\n","  pic = X[i,:,:,:].detach().numpy().transpose((1,2,0))\n","  pic = pic/2 + .5 # undo normalization\n","  axs[1,i].imshow(pic)\n","  axs[1,i].set_title(f'[ {np.min(pic):.2f}, {np.max(pic):.2f} ]',fontsize=10)\n","  axs[1,i].axis('off')\n","\n","\n","plt.show()"],"metadata":{"id":"1u6FglGyYzln"},"execution_count":null,"outputs":[]}]}
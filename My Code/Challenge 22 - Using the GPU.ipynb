{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNK0vzIhKOyVdsaIxQPdLXX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Task\n","- alter the task to run on GPU\n","- this task on CPU took about 30 minutes to run"],"metadata":{"id":"A8AKzW7GIe2a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fv3aLBzxESHX"},"outputs":[],"source":["# import libraries\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","from IPython import display\n","display.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["# import dataset (comes with colab!)\n","data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n","\n","# extract labels (number IDs) and remove from data\n","labels = data[:,0]\n","data   = data[:,1:]\n","\n","# normalize the data to a range of [0 1]\n","dataNorm = data / np.max(data)"],"metadata":{"id":"srhTIkXNIU6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: convert to tensor\n","dataT   = torch.tensor( dataNorm ).float()\n","labelsT = torch.tensor( labels ).long()\n","\n","# Step 2: use scikitlearn to split the data\n","train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n","\n","\n","# Step 3: convert into PyTorch Datasets\n","train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n","test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n","\n","# Step 4: translate into dataloader objects\n","batchsize    = 32\n","train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n","test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"],"metadata":{"id":"U1-dKHk0IVwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a class for the model\n","def createTheMNISTNet(nUnits,nLayers):\n","\n","  class mnistNet(nn.Module):\n","    def __init__(self,nUnits,nLayers):\n","      super().__init__()\n","\n","      # create dictionary to store the layers\n","      self.layers = nn.ModuleDict()\n","      self.nLayers = nLayers\n","\n","      ### input layer\n","      self.layers['input'] = nn.Linear(784,nUnits)\n","\n","      ### hidden layers\n","      for i in range(nLayers):\n","        self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n","\n","      ### output layer\n","      self.layers['output'] = nn.Linear(nUnits,10)\n","\n","\n","\n","    # forward pass\n","    def forward(self,x):\n","      # input layer (note: the code in the video omits the relu after this layer)\n","      x = F.relu( self.layers['input'](x) )\n","\n","      # hidden layers\n","      for i in range(self.nLayers):\n","        x = F.relu( self.layers[f'hidden{i}'](x) )\n","\n","      # return output layer\n","      x = self.layers['output'](x)\n","      return x\n","\n","  # create the model instance\n","  net = mnistNet(nUnits,nLayers)\n","\n","  # loss function\n","  lossfun = nn.CrossEntropyLoss()\n","\n","  # optimizer\n","  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n","\n","  return net,lossfun,optimizer"],"metadata":{"id":"o3lBsT6eIW2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate an instance of the model and confirm that it returns the expected network.\n","nUnitsPerLayer = 12\n","nLayers = 4\n","net = createTheMNISTNet(nUnitsPerLayer,nLayers)\n","net"],"metadata":{"id":"AePCgXiNIX3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a function that trains the model\n","\n","def funtion2trainTheModel(nUnits,nLayers):\n","\n","  # number of epochs\n","  numepochs = 60\n","\n","  # create a new model\n","  net,lossfun,optimizer = createTheMNISTNet(nUnits,nLayers)\n","\n","  # initialize losses\n","  losses    = torch.zeros(numepochs)\n","  trainAcc  = []\n","  testAcc   = []\n","\n","  # send the model to the GPU\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  net.to(device)\n","\n","  # loop over epochs\n","  for epochi in range(numepochs):\n","\n","    # loop over training data batches\n","    batchAcc  = []\n","    batchLoss = []\n","    for X,y in train_loader:\n","      # new\n","      X.to(device)\n","      y.to(device)\n","\n","\n","      # forward pass and loss\n","      yHat = net(X)\n","      loss = lossfun(yHat,y)\n","\n","      # backprop\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # loss from this batch\n","      batchLoss.append(loss.item())\n","\n","      # New - moving output and label to cpu\n","      yHat = yHat.cpu()\n","      y = y.cpu()\n","\n","      # compute accuracy\n","      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n","      matchesNumeric = matches.float()             # convert to numbers (0/1)\n","      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n","      batchAcc.append( accuracyPct )               # add to list of accuracies\n","    # end of batch loop...\n","\n","    # now that we've trained through the batches, get their average training accuracy\n","    trainAcc.append( np.mean(batchAcc) )\n","\n","    # and get average losses across the batches\n","    losses[epochi] = np.mean(batchLoss)\n","\n","    # test accuracy\n","    X.to(device),y.to(device) = next(iter(test_loader)) # extract X,y from test dataloader\n","    with torch.no_grad(): # deactivates autograd\n","      yHat = net(X)\n","\n","    # New - moving output and label to cpu\n","    yHat = yHat.cpu()\n","    y = y.cpu()\n","\n","    # compare the following really long line of code to the training accuracy lines\n","    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n","\n","  # end epochs\n","\n","  # function output\n","  return trainAcc,testAcc,losses,net.to('cpu')\n"],"metadata":{"id":"I4AB0f2FIY2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### run the experiment! (note: takes ~30 mins)\n","import time\n","start_time = time.process_time()\n","\n","# define the model parameters\n","numlayers = range(1,4)           # number of hidden layers\n","numunits  = np.arange(50,251,50) # units per hidden layer\n","\n","# initialize output matrices\n","accuracies  = np.zeros((2,len(numunits),len(numlayers)))\n","\n","# start the experiment!\n","for unitidx in range(len(numunits)):\n","  for layeridx in range(len(numlayers)):\n","\n","    # create and train a fresh model\n","    trainAcc,testAcc,losses,net = funtion2trainTheModel(numunits[unitidx],numlayers[layeridx])\n","\n","    # store the results (average of final 5 epochs)\n","    accuracies[0,unitidx,layeridx] = np.mean(trainAcc[-5:])\n","    accuracies[1,unitidx,layeridx] = np.mean(testAcc[-5:])\n","\n","    # print a friendly status message\n","    print(f'Finished units {unitidx+1}/{len(numunits)} and layers {layeridx+1}/{len(numlayers)}')\n","\n","end_time = time.process_time() - start_time\n","minutes = end_time // 60\n","seconds = end_time % 60\n","print(\"Processing Time: \"+end_time+\":\"+seconds)"],"metadata":{"id":"ziHzqiQeIZzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainAcc[-5:]"],"metadata":{"id":"MHcj2moDIbJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show accuracy as a function of model depth\n","fig,ax = plt.subplots(1,2,figsize=(15,6))\n","\n","ax[0].plot(numunits,accuracies[0,:,:],'o-',markerfacecolor='w',markersize=9)\n","ax[1].plot(numunits,accuracies[1,:,:],'o-',markerfacecolor='w',markersize=9)\n","\n","for i in range(2):\n","  ax[i].legend(numlayers)\n","  ax[i].set_ylabel('Accuracy')\n","  ax[i].set_xlabel('Number of hidden units')\n","  ax[i].set_title([ 'Train' if i==0 else 'Test' ][0])\n","\n","plt.show()"],"metadata":{"id":"QcjMYrmtIcLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H368IlDyIcja"},"execution_count":null,"outputs":[]}]}